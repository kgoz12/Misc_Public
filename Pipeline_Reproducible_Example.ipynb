{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "321674b7-35ef-498d-9148-3f860ed8da2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install --upgrade pip\n",
    "# %pip install torch==2.0.1\n",
    "# %pip install transformers==4.29.2\n",
    "# %pip install scikit-learn==0.24.2\n",
    "# %pip install pyspark==3.4.0\n",
    "# %pip install pandas==1.3.4\n",
    "# %pip install accelerate==0.20.3\n",
    "# %pip install pytorch-lightning==2.0.3\n",
    "# %pip install seqeval==1.2.2\n",
    "# %pip install datasets==2.14.4\n",
    "# %pip install tqdm==4.65.0\n",
    "# %pip install evaluate==0.4.0\n",
    "# %pip install mlflow==2.10.2\n",
    "# %pip install mlflow[pipelines]\n",
    "# %pip install torchvision==0.15.2\n",
    "# dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "752ecc34-6d57-4546-881f-afeb30cc4fd2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7fa0782928b0>\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import os \n",
    "import re\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, explode_outer, when,  isnull, col, arrays_zip, element_at, lower, trim, count, split, from_json\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e29d9c7e-cd11-4774-ae96-9b52b45397a2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>rowkey</th><th>text</th></tr></thead><tbody><tr><td>row123</td><td>Fluffy is taking Dasuquin. She has stopped using Cosequin.</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "row123",
         "Fluffy is taking Dasuquin. She has stopped using Cosequin."
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "rowkey",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "text",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a toy dataframe\n",
    "dff = spark.createDataFrame([[\"row123\", \"Fluffy is taking Dasuquin. She has stopped using Cosequin.\"]]).toDF(\"rowkey\", \"text\")\n",
    "display(dff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aaeac57-d655-4722-810d-334dd3b907c4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Send spark dataframe through NER model and append predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6162c90a-d439-4ca1-9d97-914321290de5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0114cfa8dd0b4187afd5c564b81fbea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/03/07 19:41:18 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n2024/03/07 19:41:31 INFO mlflow.pyfunc: This UDF will use virtualenv to recreate the model's software environment for inference. This may take extra time during execution.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778f18c179d5420ab45a09f7c99088a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/03/07 19:41:31 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n2024/03/07 19:41:31 INFO mlflow.utils.virtualenv: Installing python 3.9.5 if it does not exist\n2024/03/07 19:41:32 INFO mlflow.utils.virtualenv: Environment /local_disk0/.ephemeral_nfs/repl_tmp_data/ReplId-17ad3-b63bf-abd95-2/mlflow/envs/virtualenv_envs/mlflow-4dd7bf40bb032fc4439df332473663d872ccf4c2 already exists\n2024/03/07 19:41:32 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /local_disk0/.ephemeral_nfs/repl_tmp_data/ReplId-17ad3-b63bf-abd95-2/mlflow/envs/virtualenv_envs/mlflow-4dd7bf40bb032fc4439df332473663d872ccf4c2/bin/activate && python -c \"\"']'\n"
     ]
    }
   ],
   "source": [
    "# internally trained NER model, URI can be found in model artifacts\n",
    "logged_model_ner = 'runs:/09c916aca7ed485fa918039471ae853a/ner' \n",
    "\n",
    "# load NER model as UDF \n",
    "# the virtualenv will reproduce the environment (spark version, python version, pkg versions) used when model was trained\n",
    "model_udf = mlflow.pyfunc.spark_udf(\n",
    "    spark, \n",
    "    model_uri=logged_model_ner, \n",
    "    result_type=\"string\", # json string - will require further parsing\n",
    "    env_manager=\"virtualenv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38c54ede-8a0f-47e9-8426-d44f815d6fce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# splits text into sentences using punctuation that indicates end of sentence (.?!)\n",
    "import re\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "def split_text(text):\n",
    "    text_length = len(text)\n",
    "    finditer_output = re.finditer(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!)\\s', text)\n",
    "    sentences = re.split(r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!)\\s\", text)\n",
    "    delimiter_spans = []\n",
    "    for f in finditer_output: \n",
    "        delimiter_spans.append(list(f.span()))\n",
    "    # create an empty list to store the character index spans of the sentences\n",
    "    sentence_spans = []\n",
    "    # this counts the number of delimiters found by counting the number of items in the list\n",
    "    upper_bound = len(delimiter_spans)\n",
    "    # loop through the delimiter list, and based on criteria generate the list with the sentence spans\n",
    "    if upper_bound > 0:\n",
    "        for i in range(upper_bound+1):\n",
    "            if i == 0:\n",
    "                sentence_spans.append(list([1, delimiter_spans[0][0]-1]))\n",
    "            elif i == upper_bound:\n",
    "                sentence_spans.append(list([delimiter_spans[upper_bound-1][1]+1, text_length]))\n",
    "            else:\n",
    "                sentence_spans.append(list([delimiter_spans[(i-1)][1]+1, delimiter_spans[i][0]-1])) \n",
    "    # if there are zero sentences, then append entire note\n",
    "    else:\n",
    "        sentences = [text]\n",
    "        sentence_spans.append(list([1, text_length]))\n",
    "    # zip sentences and spans into lists eturn output to be stored in the spark table\n",
    "    sentence_and_span = [list(a) for a in zip(sentences, sentence_spans)]\n",
    "    # return the zipped sentences and spans\n",
    "    return sentence_and_span\n",
    "\n",
    "# wrap the function above as a spark udf\n",
    "split_text_udf = udf(split_text, T.ArrayType(T.StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b287f1b-cd20-4579-8f60-8938323532fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>rowkey</th><th>text</th><th>sentences_and_spans</th><th>exploded_sentences_spans</th><th>list_sentence_spans</th><th>sentence</th><th>span</th><th>sentence_span_list</th><th>sentence_span_start</th><th>sentence_span_end</th></tr></thead><tbody><tr><td>row123</td><td>Fluffy is taking Dasuquin. She has stopped using Cosequin.</td><td>List([Fluffy is taking Dasuquin., [1, 25]], [She has stopped using Cosequin., [28, 58]])</td><td>[Fluffy is taking Dasuquin., [1, 25]]</td><td>List([Fluffy is taking Dasuquin., [1, 25]])</td><td>Fluffy is taking Dasuquin.</td><td>[1, 25]</td><td>List([1, 25])</td><td>1</td><td>25</td></tr><tr><td>row123</td><td>Fluffy is taking Dasuquin. She has stopped using Cosequin.</td><td>List([Fluffy is taking Dasuquin., [1, 25]], [She has stopped using Cosequin., [28, 58]])</td><td>[She has stopped using Cosequin., [28, 58]]</td><td>List([She has stopped using Cosequin., [28, 58]])</td><td>She has stopped using Cosequin.</td><td>[28, 58]</td><td>List([28, 58])</td><td>28</td><td>58</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "row123",
         "Fluffy is taking Dasuquin. She has stopped using Cosequin.",
         [
          "[Fluffy is taking Dasuquin., [1, 25]]",
          "[She has stopped using Cosequin., [28, 58]]"
         ],
         "[Fluffy is taking Dasuquin., [1, 25]]",
         [
          "[Fluffy is taking Dasuquin.",
          "[1, 25]]"
         ],
         "Fluffy is taking Dasuquin.",
         "[1, 25]",
         [
          "[1",
          "25]"
         ],
         1,
         25
        ],
        [
         "row123",
         "Fluffy is taking Dasuquin. She has stopped using Cosequin.",
         [
          "[Fluffy is taking Dasuquin., [1, 25]]",
          "[She has stopped using Cosequin., [28, 58]]"
         ],
         "[She has stopped using Cosequin., [28, 58]]",
         [
          "[She has stopped using Cosequin.",
          "[28, 58]]"
         ],
         "She has stopped using Cosequin.",
         "[28, 58]",
         [
          "[28",
          "58]"
         ],
         28,
         58
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "rowkey",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "text",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sentences_and_spans",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "exploded_sentences_spans",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "list_sentence_spans",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":false}"
        },
        {
         "metadata": "{}",
         "name": "sentence",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "span",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sentence_span_list",
         "type": "{\"type\":\"array\",\"elementType\":\"string\",\"containsNull\":false}"
        },
        {
         "metadata": "{}",
         "name": "sentence_span_start",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "sentence_span_end",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# send dataframe through sentence parser. Retain character indexes of begin / end of sentences\n",
    "# \"1\" based indexing (not 0)\n",
    "sample_note_parsed_sentences = dff\\\n",
    "    .select(dff.rowkey,\n",
    "            dff.text,\n",
    "            split_text_udf(dff.text).alias(\"sentences_and_spans\"))\\\n",
    "    .withColumn(\"exploded_sentences_spans\", explode_outer(F.col(\"sentences_and_spans\")))\\\n",
    "    .withColumn(\"list_sentence_spans\", split(F.col(\"exploded_sentences_spans\"), \",\\s+(?=(\\[\\d+, \\d+\\]]$))\" , -1))\\\n",
    "    .withColumn(\"sentence\", F.col(\"list_sentence_spans\")[0])\\\n",
    "    .withColumn(\"span\", F.col(\"list_sentence_spans\")[1])\\\n",
    "    .withColumn(\"sentence\", F.expr(\"substring(sentence, 2, length(sentence)-1)\"))\\\n",
    "    .withColumn(\"span\", F.expr(\"substring(span, 1, length(span)-1)\"))\\\n",
    "    .withColumn(\"sentence_span_list\", split(F.col(\"span\"), \", \", -1) )\\\n",
    "    .withColumn(\"sentence_span_start\", F.col(\"sentence_span_list\")[0])\\\n",
    "    .withColumn(\"sentence_span_end\", F.col(\"sentence_span_list\")[1])\\\n",
    "    .withColumn(\"sentence_span_start\", F.expr(\"substring(sentence_span_start, 2, length(sentence_span_start)-1)\").cast(T.IntegerType()))\\\n",
    "    .withColumn(\"sentence_span_end\", F.expr(\"substring(sentence_span_end, 1, length(sentence_span_end)-1)\").cast(T.IntegerType()))\n",
    "\n",
    "display(sample_note_parsed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f3a4f0f-e57a-436a-89db-0a6cf646d58e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>rowkey</th><th>text</th><th>sentence_span_start</th><th>sentence_span_end</th><th>entity_group</th><th>score</th><th>word</th><th>start</th><th>end</th></tr></thead><tbody><tr><td>row123</td><td>Fluffy is taking Dasuquin.</td><td>1</td><td>25</td><td>Supplement</td><td>0.99635386</td><td>dasuquin</td><td>17</td><td>25</td></tr><tr><td>row123</td><td>She has stopped using Cosequin.</td><td>28</td><td>58</td><td>Supplement</td><td>0.99432075</td><td>cosequin</td><td>22</td><td>30</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "row123",
         "Fluffy is taking Dasuquin.",
         1,
         25,
         "Supplement",
         0.99635386,
         "dasuquin",
         17,
         25
        ],
        [
         "row123",
         "She has stopped using Cosequin.",
         28,
         58,
         "Supplement",
         0.99432075,
         "cosequin",
         22,
         30
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "rowkey",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "text",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sentence_span_start",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "sentence_span_end",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "entity_group",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "score",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "word",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "start",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "end",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# send sentences through model\n",
    "# if you let empty sentences (or ones that just contain \\n) into the model it will run forever then bomb\n",
    "with_ner_predictions = sample_note_parsed_sentences\\\n",
    "    .select(F.col(\"rowkey\"), F.col(\"sentence\"), F.col(\"sentence_span_start\"), F.col(\"sentence_span_end\"))\\\n",
    "    .withColumnRenamed(\"sentence\", \"text\")\\\n",
    "    .filter((F.col(\"sentence_span_end\") - F.col(\"sentence_span_start\"))>0)\\\n",
    "    .withColumn(\"prediction\", model_udf(F.col(\"text\")))\\\n",
    "    .withColumn(\"prediction_array\", \n",
    "                from_json(col(\"prediction\"), \n",
    "                          'ARRAY<STRUCT<entity_group: STRING, score: FLOAT, word: STRING, start: INT, end: INT>>')\n",
    "                )\\\n",
    "    .withColumn(\"individual_predictions\", explode(\"prediction_array\"))\\\n",
    "    .drop(\"prediction\", \"prediction_array\")\\\n",
    "    .withColumn(\"entity_group\", F.col(\"individual_predictions.entity_group\"))\\\n",
    "    .withColumn(\"score\", F.col(\"individual_predictions.score\"))\\\n",
    "    .withColumn(\"word\", F.col(\"individual_predictions.word\"))\\\n",
    "    .withColumn(\"start\", F.col(\"individual_predictions.start\"))\\\n",
    "    .withColumn(\"end\", F.col(\"individual_predictions.end\"))\\\n",
    "    .drop(\"individual_predictions\")\n",
    "\n",
    "display(with_ner_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43873b71-a075-4185-b1f8-95e63587d205",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# with_ner_predictions.write.mode(\"overwrite\").parquet(\"s3a://FAKE/FAKE\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2151444576101439,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Pipeline_Reproducible_Example",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
